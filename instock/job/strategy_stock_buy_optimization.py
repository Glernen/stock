#!/usr/local/bin/python3
# -*- coding: utf-8 -*-

# åœ¨é¡¹ç›®è¿è¡Œæ—¶ï¼Œä¸´æ—¶å°†é¡¹ç›®è·¯å¾„æ·»åŠ åˆ°ç¯å¢ƒå˜é‡
import os.path
import sys
cpath_current = os.path.dirname(os.path.dirname(__file__))
cpath = os.path.abspath(os.path.join(cpath_current, os.pardir))
sys.path.append(cpath)

import argparse
import logging
import time
from datetime import datetime, timedelta
import pandas as pd
import sqlalchemy
from sqlalchemy import MetaData, Table, text
from tqdm import tqdm
from instock.lib.database import db_host, db_user, db_password, db_database, db_charset 
import instock.lib.database as mdb
import instock.core.tablestructure as tbs

__author__ = 'hqm'
__date__ = '2025/4/15'

# åœ¨æ–‡ä»¶é¡¶éƒ¨å®šä¹‰å›æµ‹å­—æ®µé…ç½®ï¼ˆæ›¿æ¢tbsæ¨¡å—çš„å¼•ç”¨ï¼‰
RATE_FIELDS_COUNT = 100
TABLE_CN_STOCK_BACKTEST_DATA = {
    'columns': {
        f'rate_{i}': {'type': 'FLOAT', 'cn': f'{i}æ—¥æ”¶ç›Šç‡'} 
        for i in range(1, RATE_FIELDS_COUNT + 1)
    }
}

table_name = "strategy_stock_buy_optimization"

def validate_date(date_str):
    """éªŒè¯æ—¥æœŸæ ¼å¼æ˜¯å¦ä¸ºYYYYMMDD"""
    try:
        datetime.strptime(date_str, "%Y%m%d")
        return int(date_str)
    except ValueError:
        raise argparse.ArgumentTypeError(f"æ— æ•ˆçš„æ—¥æœŸæ ¼å¼: {date_str}ï¼Œåº”ä½¿ç”¨YYYYMMDDæ ¼å¼")

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='è‚¡ç¥¨åˆ†æå·¥å…·')
    parser.add_argument('dates', nargs='*', type=validate_date,
                       help='åˆ†ææ—¥æœŸ(æ”¯æŒ1-2ä¸ªYYYYMMDDæ ¼å¼æ—¥æœŸ)')
    return parser.parse_args()

def get_default_dates():
    """è·å–é»˜è®¤æ—¥æœŸï¼ˆæœ€è¿‘3ä¸ªäº¤æ˜“æ—¥ï¼‰"""
    # è¿™é‡Œéœ€è¦å®ç°è·å–çœŸå®äº¤æ˜“æ—¥é€»è¾‘ï¼Œç¤ºä¾‹ä½¿ç”¨é™æ€æ•°æ®
    today = datetime.now().strftime("%Y%m%d")
    return [int(today)]

def build_date_condition(start_date, end_date=None):
    """æ„å»ºSQLæ—¥æœŸæ¡ä»¶"""
    if end_date is None or start_date == end_date:
        return f"csi.date_int = {start_date}"
    return f"csi.date_int BETWEEN {start_date} AND {end_date}"

def guess_buy(start_date_int, end_date_int=None):
    """æ ¸å¿ƒåˆ†æé€»è¾‘"""
    try:
        # è·å–ç­–ç•¥æ¡ä»¶
        # strategy_cond = STRATEGY_CONFIG.get(strategy_name, {}).get('conditions')
        # if not strategy_cond:
        #     raise ValueError(f"æœªçŸ¥ç­–ç•¥: {strategy_name}")

        # ç¡®ä¿è¡¨å­˜åœ¨
        create_optimized_table()
        
        # æ„å»ºåŠ¨æ€æ—¥æœŸæ¡ä»¶
        date_condition = build_date_condition(start_date_int, end_date_int)

        sql = f"""
        WITH latest_date AS (
            SELECT 
                MAX(`date_int`) AS latest_date_int
            FROM 
                `stock_3day_indicators`
        ),
        buy_all AS (
            SELECT *
            FROM 
                `cn_stock_indicators_buy` csi
        --     JOIN latest_date ON csi.`date_int` = latest_date.latest_date_int
            WHERE 
                
                -- AND csi.`date_int` > 20250409
                {date_condition}
                AND csi.`rate_60` IS NULL 
                AND (csi.`strategy` = 'strategy_a' OR csi.`strategy` = 'strategy_b') 
                -- AND csi.`industry_kdj` = 'ä¸Šæ¶¨è¶‹åŠ¿' 
                AND csi.`code` NOT LIKE '688%' 
                AND csi.`code` NOT LIKE '8%' 
            AND (
            -- å¤§ç›˜å¼ºåŠ¿ä¸Šæ¶¨ï¼šå¤§ç›˜æŒ‡æ ‡ä¸Šæ¶¨ï¼Œè¡Œä¸šæŒ‡æ ‡ä¸Šæ¶¨ï¼Œä¸ªè‚¡æ¢æ‰‹ç‡å°äº20%çš„ç²¾ç­›è‚¡
                    (csi.`up_sentiment` > 10
                AND csi.`up_sentiment` < 50
                AND csi.`down_sentiment` = 0
                AND csi.`industry_kdj` = 'ä¸Šæ¶¨è¶‹åŠ¿'
                AND csi.`industry_kdjj` < 60
                AND csi.`industry_sentiment` = 'è¡Œä¸šéœ‡è¡ä¸­æ€§'
                AND csi.`turnover` > 1
                AND csi.`industry_cci` != 'æ–¹å‘ä¸æ˜')
            -- å¤§ç›˜å¼ºåŠ¿ä¸Šæ¶¨ï¼šå¤§ç›˜æŒ‡æ ‡ä¸Šæ¶¨ï¼Œè¡Œä¸šæŒ‡æ ‡ä¸Šæ¶¨
            OR (csi.`up_sentiment` >= 50
                AND csi.`down_sentiment` = 0
                AND csi.`industry_kdj` = 'ä¸Šæ¶¨è¶‹åŠ¿'
                AND csi.`industry_sentiment` = 'è¡Œä¸šå¼ºåŠ¿çœ‹æ¶¨'
                and csi.`turnover` > 0.5
                AND csi.`industry_cci` != 'æ–¹å‘ä¸æ˜' )
            --     -- å¤§ç›˜éœ‡è¡æœŸï¼šå¤§ç›˜æŒ‡æ ‡ä¸Šæ¶¨ï¼ˆæŒ‡æ•°Kå€¼å°äº60ä¸ºæ ‡å‡†ï¼‰å°äº2ä¸ªæŒ‡æ•°ç›˜ï¼Œè¡Œä¸šæŒ‡æ ‡ä¸Šæ¶¨ï¼Œä¸ªè‚¡æ¢æ‰‹ç‡å°äº20%çš„ç²¾ç­›è‚¡
            OR (csi.`up_sentiment` <= 20
                AND csi.`industry_kdj` = 'ä¸Šæ¶¨è¶‹åŠ¿'
                AND csi.`industry_wr` = 'æŒç»­è¶…ä¹°'
                AND csi.`turnover` < 20)
            --     -- å¤§ç›˜ä¸Šæ¶¨åˆç°ï¼šå¤§ç›˜æŒ‡æ ‡ä¸Šæ¶¨ï¼Œè¡Œä¸šæŒ‡æ ‡æœªå¢™è£‚ä¸Šæ¶¨ä¸”å¤„äºè¶…å–åŒºï¼Œä¸ªè‚¡æ¢æ‰‹ç‡å¤§äº1%çš„ç²¾ç­›è‚¡
            OR (csi.`up_sentiment` >= 30
                AND csi.`down_sentiment` = 0
                AND csi.`industry_kdj` = 'ä¸‹é™è¶‹åŠ¿'
                AND csi.`industry_kdjj` < 20
                AND csi.`industry_sentiment` = 'è¡Œä¸šéœ‡è¡ä¸­æ€§'
                AND csi.`turnover` > 1)
                )
        )
        SELECT * 
        FROM buy_all 
        """
        
        with mdb.engine().connect() as conn:
            data = pd.read_sql(text(sql), conn)
        
        if data.empty:
            logging.info("æ— ç¬¦åˆæ¡ä»¶çš„æ•°æ®")
            return

        # æ–°å¢åˆ—åˆå¹¶é€»è¾‘ï¼ˆå…³é”®ä¿®æ”¹ç‚¹ï¼‰
        _columns_backtest = tuple(TABLE_CN_STOCK_BACKTEST_DATA['columns'])
        data = pd.concat([data, pd.DataFrame(columns=_columns_backtest)])

        # ç§»é™¤è°ƒè¯•ç”¨çš„é”™è¯¯printè¯­å¥ï¼Œæ›¿æ¢ä¸ºæ—¥å¿—è¾“å‡º
        logging.debug(f"å¤„ç†æ—¥æœŸèŒƒå›´: {start_date_int} è‡³ {end_date_int or start_date_int}")

        # print(f'{data}')

        # æ’å…¥æ•°æ®åº“é€»è¾‘ï¼ˆä½¿ç”¨ä¼˜åŒ–åçš„æ’å…¥æ–¹æ³•ï¼‰
        optimized_data_insert(data)
        
    except Exception as e:
        logging.error(f"å¤„ç†å¼‚å¸¸ï¼š{e}")
        raise

# sqlå­—æ®µåï¼šup_sentiment,down_sentiment,code,name,date_int,kdjj,jingliuru_cn,close,turnover,industry,industry_kdjj,industry_kdjj_day1,industry_kdj,industry_wr,industry_cci,industry_sentiment
# ä¿®æ”¹è¡¨ç»“æ„ï¼ˆæ–°å¢å­—æ®µï¼‰
def create_optimized_table():
    create_table_sql = f"""
    CREATE TABLE IF NOT EXISTS `{table_name}` (
        `id` INT AUTO_INCREMENT PRIMARY KEY,
        `date` DATE NOT NULL,
        `date_int` INT NOT NULL COMMENT 'æ—¥æœŸYYYYMMDDæ ¼å¼',
        `code` VARCHAR(6) NOT NULL COMMENT 'è‚¡ç¥¨ä»£ç ',
        `code_int` INT NOT NULL COMMENT 'æ•´æ•°æ ¼å¼è‚¡ç¥¨ä»£ç ',
        `name` VARCHAR(20) COMMENT 'è‚¡ç¥¨åç§°',
        `strategy` VARCHAR(50) NOT NULL COMMENT 'ç­–ç•¥æ ‡è¯†',
        `close` FLOAT COMMENT 'æ”¶ç›˜ä»·',
        `kdjj` FLOAT COMMENT 'è‚¡ç¥¨å½“å¤©Jå€¼',
        `turnover` FLOAT COMMENT 'æ¢æ‰‹ç‡',
        `jingliuru_cn` VARCHAR(50) COMMENT 'å‡€æµå…¥',
        `industry` VARCHAR(50) COMMENT 'æ‰€å±è¡Œä¸š',
        `up_sentiment` INT COMMENT 'å¤§ç›˜ä¸Šæ¶¨æƒ…ç»ª',
        `down_sentiment` INT COMMENT 'å¤§ç›˜ä¸‹è·Œæƒ…ç»ª',
        `industry_kdjj` FLOAT COMMENT 'è¡Œä¸šå½“å¤©Jå€¼',
        `industry_kdjj_day1` FLOAT COMMENT 'è¡Œä¸šå‰ä¸€å¤©Jå€¼',
        `industry_kdj` VARCHAR(50) COMMENT 'è¡Œä¸šKDJè¶‹åŠ¿',
        `industry_wr` VARCHAR(50) COMMENT 'è¡Œä¸šå¨å»‰è¶‹åŠ¿',
        `industry_cci` VARCHAR(50) COMMENT 'è¡Œä¸šCCIè¶‹åŠ¿',
        `industry_sentiment` VARCHAR(50) COMMENT 'è¡Œä¸šä¹°å–æƒ…ç»ª',
        /* æ–°å¢å›æµ‹å­—æ®µ */
        {' ,'.join([f'`{col}` FLOAT' for col in TABLE_CN_STOCK_BACKTEST_DATA['columns']])},
        UNIQUE KEY `idx_unique` (`date_int`,`code_int`,`strategy`),
        KEY `idx_code` (`code_int`),
        KEY `idx_date` (`date_int`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci COMMENT='é€‰è‚¡ç»“æœä¼˜åŒ–è¡¨';
    """
    
    # ä½¿ç”¨æ–°çš„è¿æ¥æ£€æŸ¥å¹¶åˆ›å»ºè¡¨
    with mdb.engine().connect() as conn:
        try:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            if not conn.dialect.has_table(conn, table_name):
                conn.execute(text(create_table_sql))
                conn.commit()
                logging.info(f"è¡¨ {table_name} åˆ›å»ºæˆåŠŸ")
            else:
                # æ£€æŸ¥å¹¶æ·»åŠ ç¼ºå°‘çš„åˆ—ï¼ˆå¯é€‰ï¼‰
                pass
        except Exception as e:
            logging.error(f"åˆ›å»ºè¡¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            raise



def optimized_data_insert(data):
    try:
        with mdb.engine().connect() as conn:
            metadata = MetaData()
            table = Table(table_name, metadata, autoload_with=conn.engine)
            
            # è°ƒè¯•ï¼šæ‰“å°è¡¨ç»“æ„
            # print("\n[DEBUG] è¡¨ç»“æ„å­—æ®µï¼š")
            # for col in table.columns:
            #     print(f"{col.name}: {col.type}")
                
            unique_keys = {'date_int', 'code_int', 'strategy'}
            update_columns = [
                col.name for col in table.columns 
                if col.name not in unique_keys 
                and col.name != 'id'
            ]
            # print(f"\n[DEBUG] å°†æ›´æ–°çš„å­—æ®µï¼š{update_columns}")

            # éªŒè¯æ•°æ®å­—æ®µåŒ¹é…
            missing_columns = set(data.columns) - {col.name for col in table.columns}
            if missing_columns:
                raise ValueError(f"æ•°æ®åŒ…å«è¡¨ä¸­ä¸å­˜åœ¨çš„åˆ—: {missing_columns}")

        def upsert_data(table, conn, keys, data_iter):
            from sqlalchemy.dialects.mysql import insert
            
            data_rows = [dict(zip(keys, row)) for row in data_iter]
            if not data_rows:
                return
                
            stmt = insert(table.table).values(data_rows)
            update_dict = {col: stmt.inserted[col] for col in update_columns}
            
            # è°ƒè¯•ï¼šæ‰“å°ç”Ÿæˆçš„SQL
            compiled_stmt = stmt.on_duplicate_key_update(**update_dict).compile(
                compile_kwargs={"literal_binds": True}
            )
            # print(f"\n[DEBUG] æ‰§è¡ŒSQL:\n{compiled_stmt}")
            
            result = conn.execute(stmt.on_duplicate_key_update(**update_dict))
            # print(f"[DEBUG] å½±å“è¡Œæ•°: {result.rowcount}")

        data.to_sql(
            name=table_name,
            con=mdb.engine(),
            if_exists='append',
            index=False,
            chunksize=500,  # å‡å°chunksizeä¾¿äºè°ƒè¯•
            method=upsert_data
        )
        # print("æ•°æ®æ’å…¥/æ›´æ–°æˆåŠŸ")
        logging.info("æ•°æ®æ’å…¥/æ›´æ–°æˆåŠŸ")
        
    except Exception as e:
        logging.error(f"æ“ä½œå¤±è´¥ï¼Œè¯¦ç»†é”™è¯¯ï¼š{str(e)}", exc_info=True)
        raise



def main():
    """ä¸»å…¥å£å‡½æ•°"""
    start_time = time.time()
    try:
        args = parse_arguments()
        
        # å¤„ç†æ—¥æœŸå‚æ•°
        if len(args.dates) == 0:
            dates = get_default_dates()
            if len(dates) == 1:
                start_date = end_date = dates[0]
            else:
                start_date, end_date = dates[0], dates[-1]
        elif len(args.dates) == 1:
            start_date = end_date = args.dates[0]
        elif len(args.dates) == 2:
            start_date, end_date = sorted(args.dates)
            if start_date > end_date:
                raise ValueError("å¼€å§‹æ—¥æœŸä¸èƒ½æ™šäºç»“æŸæ—¥æœŸ")
        else:
            print("å‚æ•°é”™è¯¯ï¼æ”¯æŒä»¥ä¸‹è°ƒç”¨æ–¹å¼ï¼š")
            print("1. æ— å‚æ•°       -> è‡ªåŠ¨ä½¿ç”¨æœ€è¿‘äº¤æ˜“æ—¥")
            print("2. å•æ—¥æœŸ       -> python script.py 20230101")
            print("3. æ—¥æœŸåŒºé—´     -> python script.py 20230101 20230105")
            return


        guess_buy(
            start_date_int=start_date,
            end_date_int=end_date
        )
        
    except Exception as e:
        logging.error(f"æ‰§è¡Œå¤±è´¥: {e}")
    finally:
        print(f"strategy_stock_buy_optimization\nğŸ•’ æ€»è€—æ—¶: {time.time()-start_time:.2f}ç§’")  # ç¡®ä¿å¼‚å¸¸æ—¶ä¹Ÿè¾“å‡º

if __name__ == '__main__':
    main()
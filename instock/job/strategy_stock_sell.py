#!/usr/local/bin/python3
# -*- coding: utf-8 -*-

# åœ¨é¡¹ç›®è¿è¡Œæ—¶ï¼Œä¸´æ—¶å°†é¡¹ç›®è·¯å¾„æ·»åŠ åˆ°ç¯å¢ƒå˜é‡
import os.path
import sys
cpath_current = os.path.dirname(os.path.dirname(__file__))
cpath = os.path.abspath(os.path.join(cpath_current, os.pardir))
sys.path.append(cpath)

import argparse
import logging
import time
from datetime import datetime, timedelta
import pandas as pd
import sqlalchemy
from sqlalchemy import MetaData, Table, text
from tqdm import tqdm
from instock.lib.database import db_host, db_user, db_password, db_database, db_charset 
import instock.lib.database as mdb
import instock.core.tablestructure as tbs

__author__ = 'hqm'
__date__ = '2025/4/15'

table_name = "cn_stock_indicators_sell"

# åœ¨æ–‡ä»¶é¡¶éƒ¨å®šä¹‰å›æµ‹å­—æ®µé…ç½®ï¼ˆæ›¿æ¢tbsæ¨¡å—çš„å¼•ç”¨ï¼‰
RATE_FIELDS_COUNT = 100
TABLE_CN_STOCK_BACKTEST_DATA = {
    'columns': {
        f'rate_{i}': {'type': 'FLOAT', 'cn': f'{i}æ—¥æ”¶ç›Šç‡'} 
        for i in range(1, RATE_FIELDS_COUNT + 1)
    }
}

# sqlå­—æ®µåï¼šup_sentiment,down_sentiment,code,name,date_int,kdjj,jingliuru_cn,close,turnover,industry,industry_kdjj,industry_kdjj_day1,industry_kdj,industry_wr,industry_cci,industry_sentiment
# åœ¨æ–‡ä»¶é¡¶éƒ¨æ–°å¢ç­–ç•¥é…ç½®
STRATEGY_CONFIG = {
    'strategy_a': {
        'conditions': """
            AND ä¸‰æ—¥æŒ‡æ ‡.kdjd >= 70  -- då¤„äºè¶…ä¹°åŒºåŸŸ
            AND ä¸‰æ—¥æŒ‡æ ‡.kdjj >= 85  -- jå¤„äºè¶…ä¹°åŒºåŸŸ
            AND ä¸‰æ—¥æŒ‡æ ‡.cci >= 110 
            AND ä¸‰æ—¥æŒ‡æ ‡.rsi_6 >= 65
            AND ä¸‰æ—¥æŒ‡æ ‡.rsi_12 >= 65  
            AND ABS(ä¸‰æ—¥æŒ‡æ ‡.wr_6) <= 5
        """
    },
    'strategy_b': {
        'conditions': """

        """
    }
}


def validate_date(date_str):
    """éªŒè¯æ—¥æœŸæ ¼å¼æ˜¯å¦ä¸ºYYYYMMDD"""
    try:
        datetime.strptime(date_str, "%Y%m%d")
        return int(date_str)
    except ValueError:
        raise argparse.ArgumentTypeError(f"æ— æ•ˆçš„æ—¥æœŸæ ¼å¼: {date_str}ï¼Œåº”ä½¿ç”¨YYYYMMDDæ ¼å¼")

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='è‚¡ç¥¨åˆ†æå·¥å…·')
    parser.add_argument('dates', nargs='*', type=validate_date,
                       help='åˆ†ææ—¥æœŸ(æ”¯æŒ1-2ä¸ªYYYYMMDDæ ¼å¼æ—¥æœŸ)')
    return parser.parse_args()

def get_default_dates():
    """è·å–é»˜è®¤æ—¥æœŸï¼ˆæœ€è¿‘3ä¸ªäº¤æ˜“æ—¥ï¼‰"""
    # è¿™é‡Œéœ€è¦å®ç°è·å–çœŸå®äº¤æ˜“æ—¥é€»è¾‘ï¼Œç¤ºä¾‹ä½¿ç”¨é™æ€æ•°æ®
    today = datetime.now().strftime("%Y%m%d")
    return [int(today)]

def build_date_condition(start_date, end_date=None):
    """æ„å»ºSQLæ—¥æœŸæ¡ä»¶"""
    if end_date is None or start_date == end_date:
        return f"ä¸‰æ—¥æŒ‡æ ‡.date_int = {start_date}"
    return f"ä¸‰æ—¥æŒ‡æ ‡.date_int BETWEEN {start_date} AND {end_date}"

def guess_buy(strategy_name, start_date_int, end_date_int=None):
    """æ ¸å¿ƒåˆ†æé€»è¾‘"""
    try:
        # è·å–ç­–ç•¥æ¡ä»¶
        strategy_cond = STRATEGY_CONFIG.get(strategy_name, {}).get('conditions')
        if not strategy_cond:
            raise ValueError(f"æœªçŸ¥ç­–ç•¥: {strategy_name}")

        # ç¡®ä¿è¡¨å­˜åœ¨
        create_optimized_table()
        
        # æ„å»ºåŠ¨æ€æ—¥æœŸæ¡ä»¶
        date_condition = build_date_condition(start_date_int, end_date_int)

        sql = f"""
        SELECT
            å¤§ç›˜æƒ…ç»ª.æŒ‡æ•°ä¸Šæ¶¨æƒ…ç»ª AS up_sentiment,
            å¤§ç›˜æƒ…ç»ª.æŒ‡æ•°ä¸‹è·Œæƒ…ç»ª AS down_sentiment,
        --     å¤§ç›˜æƒ…ç»ª.æ“ä½œå»ºè®®,
            ä¸‰æ—¥æŒ‡æ ‡.code ,
            ä¸‰æ—¥æŒ‡æ ‡.code_int ,
            ä¸‰æ—¥æŒ‡æ ‡.name ,
            ä¸‰æ—¥æŒ‡æ ‡.date ,
            ä¸‰æ—¥æŒ‡æ ‡.date_int ,
            ä¸‰æ—¥æŒ‡æ ‡.kdjj,
            èµ„é‡‘.jingliuru_cn ,
            ä¸‰æ—¥æŒ‡æ ‡.close ,
            ä¸‰æ—¥æŒ‡æ ‡.turnover ,
            ä¸‰æ—¥æŒ‡æ ‡.industry ,
            è¡Œä¸šæŒ‡æ ‡.kdjj AS industry_kdjj,
            è¡Œä¸šæŒ‡æ ‡.kdjj_day1 AS industry_kdjj_day1,
        --     è¡Œä¸šæ•°æ®.è¡Œä¸šåç§°,
            è¡Œä¸šæ•°æ®.KDJè¶‹åŠ¿ AS industry_kdj,
            è¡Œä¸šæ•°æ®.WRè¶‹åŠ¿ AS industry_wr,
            è¡Œä¸šæ•°æ®.CCIè¶‹åŠ¿ AS industry_cci,
        --     è¡Œä¸šæ•°æ®.å¼ºçƒˆä¹°å…¥ä¿¡å·,
        --     è¡Œä¸šæ•°æ®.å¼ºçƒˆå–å‡ºä¿¡å·,
            è¡Œä¸šæ•°æ®.è¡Œä¸šæƒ…ç»ª  AS industry_sentiment
        FROM
            stock_3day_indicators ä¸‰æ—¥æŒ‡æ ‡
            LEFT JOIN cn_stock_info åŸºç¡€ä¿¡æ¯ ON åŸºç¡€ä¿¡æ¯.code_int = ä¸‰æ—¥æŒ‡æ ‡.code_int
            LEFT JOIN stock_zijin èµ„é‡‘ ON èµ„é‡‘.code_int = ä¸‰æ—¥æŒ‡æ ‡.code_int AND èµ„é‡‘.date_int = ä¸‰æ—¥æŒ‡æ ‡.date_int
            LEFT JOIN market_sentiment_a å¤§ç›˜æƒ…ç»ª ON å¤§ç›˜æƒ…ç»ª.date_int = ä¸‰æ—¥æŒ‡æ ‡.date_int
            LEFT JOIN industry_3day_indicators è¡Œä¸šæŒ‡æ ‡ ON è¡Œä¸šæŒ‡æ ‡.name = ä¸‰æ—¥æŒ‡æ ‡.industry AND è¡Œä¸šæŒ‡æ ‡.date_int = ä¸‰æ—¥æŒ‡æ ‡.date_int
            LEFT JOIN industry_sentiment_a è¡Œä¸šæ•°æ® ON è¡Œä¸šæ•°æ®.è¡Œä¸šåç§° = ä¸‰æ—¥æŒ‡æ ‡.industry AND è¡Œä¸šæ•°æ®.date_int = ä¸‰æ—¥æŒ‡æ ‡.date_int
        WHERE 
            {date_condition}
            {strategy_cond}  # æ’å…¥ç­–ç•¥ç‰¹å®šæ¡ä»¶
            AND ä¸‰æ—¥æŒ‡æ ‡.NAME NOT LIKE '%ST%' 
            AND åŸºç¡€ä¿¡æ¯.industry NOT REGEXP 'é…¿é…’è¡Œä¸š|ç¾å®¹æŠ¤ç†|å†œè¯å…½è¯|é£Ÿå“é¥®æ–™|å…‰ä¼è®¾å¤‡|ç…¤ç‚­è¡Œä¸š|é€ çº¸å°åˆ·|ä¿é™©' 
        ORDER BY
            ä¸‰æ—¥æŒ‡æ ‡.date_int;
        """
        
        with mdb.engine().connect() as conn:
            data = pd.read_sql(text(sql), conn)
        
        if data.empty:
            logging.info("æ— ç¬¦åˆæ¡ä»¶çš„æ•°æ®")
            return

        # æ–°å¢åˆ—åˆå¹¶é€»è¾‘ï¼ˆå…³é”®ä¿®æ”¹ç‚¹ï¼‰
        _columns_backtest = tuple(TABLE_CN_STOCK_BACKTEST_DATA['columns'])
        data = pd.concat([data, pd.DataFrame(columns=_columns_backtest)])

        # æ·»åŠ ç­–ç•¥æ ‡è¯†
        data['strategy'] = strategy_name

        # ç§»é™¤è°ƒè¯•ç”¨çš„é”™è¯¯printè¯­å¥ï¼Œæ›¿æ¢ä¸ºæ—¥å¿—è¾“å‡º
        logging.debug(f"å¤„ç†æ—¥æœŸèŒƒå›´: {start_date_int} è‡³ {end_date_int or start_date_int}")

        # print(f'{data}')

        # æ’å…¥æ•°æ®åº“é€»è¾‘ï¼ˆä½¿ç”¨ä¼˜åŒ–åçš„æ’å…¥æ–¹æ³•ï¼‰
        optimized_data_insert(data)
        
    except Exception as e:
        logging.error(f"å¤„ç†å¼‚å¸¸ï¼š{e}")
        raise

# sqlå­—æ®µåï¼šup_sentiment,down_sentiment,code,name,date_int,kdjj,jingliuru_cn,close,turnover,industry,industry_kdjj,industry_kdjj_day1,industry_kdj,industry_wr,industry_cci,industry_sentiment
# ä¿®æ”¹è¡¨ç»“æ„ï¼ˆæ–°å¢å­—æ®µï¼‰
def create_optimized_table():
    # table_name = "cn_stock_indicators_sell"
    create_table_sql = f"""
    CREATE TABLE IF NOT EXISTS `{table_name}` (
        `id` INT AUTO_INCREMENT PRIMARY KEY,
        `date` DATE NOT NULL,
        `date_int` INT NOT NULL COMMENT 'æ—¥æœŸYYYYMMDDæ ¼å¼',
        `code` VARCHAR(6) NOT NULL COMMENT 'è‚¡ç¥¨ä»£ç ',
        `code_int` INT NOT NULL COMMENT 'æ•´æ•°æ ¼å¼è‚¡ç¥¨ä»£ç ',
        `name` VARCHAR(20) COMMENT 'è‚¡ç¥¨åç§°',
        `strategy` VARCHAR(50) NOT NULL COMMENT 'ç­–ç•¥æ ‡è¯†',
        `close` FLOAT COMMENT 'æ”¶ç›˜ä»·',
        `kdjj` FLOAT COMMENT 'è‚¡ç¥¨å½“å¤©Jå€¼',
        `turnover` FLOAT COMMENT 'æ¢æ‰‹ç‡',
        `jingliuru_cn` VARCHAR(50) COMMENT 'å‡€æµå…¥',
        `industry` VARCHAR(50) COMMENT 'æ‰€å±è¡Œä¸š',
        `up_sentiment` INT COMMENT 'å¤§ç›˜ä¸Šæ¶¨æƒ…ç»ª',
        `down_sentiment` INT COMMENT 'å¤§ç›˜ä¸‹è·Œæƒ…ç»ª',
        `industry_kdjj` FLOAT COMMENT 'è¡Œä¸šå½“å¤©Jå€¼',
        `industry_kdjj_day1` FLOAT COMMENT 'è¡Œä¸šå‰ä¸€å¤©Jå€¼',
        `industry_kdj` VARCHAR(50) COMMENT 'è¡Œä¸šKDJè¶‹åŠ¿',
        `industry_wr` VARCHAR(50) COMMENT 'è¡Œä¸šå¨å»‰è¶‹åŠ¿',
        `industry_cci` VARCHAR(50) COMMENT 'è¡Œä¸šCCIè¶‹åŠ¿',
        `industry_sentiment` VARCHAR(50) COMMENT 'è¡Œä¸šä¹°å–æƒ…ç»ª',
        /* æ–°å¢å›æµ‹å­—æ®µ */
        {' ,'.join([f'`{col}` FLOAT' for col in TABLE_CN_STOCK_BACKTEST_DATA['columns']])},
        UNIQUE KEY `idx_unique` (`date_int`,`code_int`,`strategy`),
        KEY `idx_code` (`code_int`),
        KEY `idx_date` (`date_int`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci COMMENT='é€‰è‚¡ç»“æœè¡¨';
    """
    
    # ä½¿ç”¨æ–°çš„è¿æ¥æ£€æŸ¥å¹¶åˆ›å»ºè¡¨
    with mdb.engine().connect() as conn:
        try:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            if not conn.dialect.has_table(conn, table_name):
                conn.execute(text(create_table_sql))
                conn.commit()
                logging.info(f"è¡¨ {table_name} åˆ›å»ºæˆåŠŸ")
            else:
                # æ£€æŸ¥å¹¶æ·»åŠ ç¼ºå°‘çš„åˆ—ï¼ˆå¯é€‰ï¼‰
                pass
        except Exception as e:
            logging.error(f"åˆ›å»ºè¡¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            raise



def optimized_data_insert(data):
    # table_name = "cn_stock_indicators_sell"
    try:
        with mdb.engine().connect() as conn:
            metadata = MetaData()
            table = Table(table_name, metadata, autoload_with=conn.engine)
            
            # è°ƒè¯•ï¼šæ‰“å°è¡¨ç»“æ„
            # print("\n[DEBUG] è¡¨ç»“æ„å­—æ®µï¼š")
            # for col in table.columns:
            #     print(f"{col.name}: {col.type}")
                
            unique_keys = {'date_int', 'code_int', 'strategy'}
            update_columns = [
                col.name for col in table.columns 
                if col.name not in unique_keys 
                and col.name != 'id'
            ]
            # print(f"\n[DEBUG] å°†æ›´æ–°çš„å­—æ®µï¼š{update_columns}")

            # éªŒè¯æ•°æ®å­—æ®µåŒ¹é…
            missing_columns = set(data.columns) - {col.name for col in table.columns}
            if missing_columns:
                raise ValueError(f"æ•°æ®åŒ…å«è¡¨ä¸­ä¸å­˜åœ¨çš„åˆ—: {missing_columns}")

        def upsert_data(table, conn, keys, data_iter):
            from sqlalchemy.dialects.mysql import insert
            
            data_rows = [dict(zip(keys, row)) for row in data_iter]
            if not data_rows:
                return
                
            stmt = insert(table.table).values(data_rows)
            update_dict = {col: stmt.inserted[col] for col in update_columns}
            
            # è°ƒè¯•ï¼šæ‰“å°ç”Ÿæˆçš„SQL
            compiled_stmt = stmt.on_duplicate_key_update(**update_dict).compile(
                compile_kwargs={"literal_binds": True}
            )
            # print(f"\n[DEBUG] æ‰§è¡ŒSQL:\n{compiled_stmt}")
            
            result = conn.execute(stmt.on_duplicate_key_update(**update_dict))
            # print(f"[DEBUG] å½±å“è¡Œæ•°: {result.rowcount}")

        data.to_sql(
            name=table_name,
            con=mdb.engine(),
            if_exists='append',
            index=False,
            chunksize=500,  # å‡å°chunksizeä¾¿äºè°ƒè¯•
            method=upsert_data
        )
        # print("æ•°æ®æ’å…¥/æ›´æ–°æˆåŠŸ")
        logging.info("æ•°æ®æ’å…¥/æ›´æ–°æˆåŠŸ")
        
    except Exception as e:
        logging.error(f"æ“ä½œå¤±è´¥ï¼Œè¯¦ç»†é”™è¯¯ï¼š{str(e)}", exc_info=True)
        raise


def main():
    """ä¸»å…¥å£å‡½æ•°"""
    start_time = time.time()
    try:
        args = parse_arguments()
        
        # å¤„ç†æ—¥æœŸå‚æ•°
        if len(args.dates) == 0:
            dates = get_default_dates()
            if len(dates) == 1:
                start_date = end_date = dates[0]
            else:
                start_date, end_date = dates[0], dates[-1]
        elif len(args.dates) == 1:
            start_date = end_date = args.dates[0]
        elif len(args.dates) == 2:
            start_date, end_date = sorted(args.dates)
            if start_date > end_date:
                raise ValueError("å¼€å§‹æ—¥æœŸä¸èƒ½æ™šäºç»“æŸæ—¥æœŸ")
        else:
            print("å‚æ•°é”™è¯¯ï¼æ”¯æŒä»¥ä¸‹è°ƒç”¨æ–¹å¼ï¼š")
            print("1. æ— å‚æ•°       -> è‡ªåŠ¨ä½¿ç”¨æœ€è¿‘äº¤æ˜“æ—¥")
            print("2. å•æ—¥æœŸ       -> python script.py 20230101")
            print("3. æ—¥æœŸåŒºé—´     -> python script.py 20230101 20230105")
            return

        # å®šä¹‰è¦è¿è¡Œçš„ç­–ç•¥åˆ—è¡¨
        strategies = ['strategy_a']
        
        # éå†æ‰§è¡Œæ‰€æœ‰ç­–ç•¥
        for strategy in strategies:
            logging.info(f"æ­£åœ¨æ‰§è¡Œç­–ç•¥: {strategy}")
            guess_buy(
                strategy_name=strategy,
                start_date_int=start_date,
                end_date_int=end_date
            )
        
    except Exception as e:
        logging.error(f"æ‰§è¡Œå¤±è´¥: {e}")
    finally:
        print(f"strategy_stock_sell\nğŸ•’ æ€»è€—æ—¶: {time.time()-start_time:.2f}ç§’")  # ç¡®ä¿å¼‚å¸¸æ—¶ä¹Ÿè¾“å‡º


if __name__ == '__main__':

    main()